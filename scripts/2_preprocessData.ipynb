{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e728ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 16:03:41.431895: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-13 16:03:41.451530: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-13 16:03:41.484728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749805421.509629   20974 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749805421.517633   20974 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749805421.542652   20974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749805421.542692   20974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749805421.542698   20974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749805421.542702   20974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-13 16:03:41.552074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9887c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = os.getcwd()\n",
    "ws_path = os.path.dirname(folder_path)\n",
    "ws_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0005b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir = os.listdir(ws_path)\n",
    "frame_path = ws_path + '/rawFrame'\n",
    "prepro_data_path = ws_path + '/preproDataset'\n",
    "nor_fr_path = frame_path + '/normal'\n",
    "vsd_fr_path = frame_path + '/vsd'\n",
    "nor_prepro_path = prepro_data_path + '/normal'\n",
    "vsd_prepro_path = prepro_data_path + '/vsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8563d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs(prepro_data_path, exist_ok=True)\n",
    "os.makedirs(nor_prepro_path, exist_ok=True)\n",
    "os.makedirs(vsd_prepro_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973da7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_img = os.listdir(nor_fr_path)\n",
    "nor_fr_list_path = list()\n",
    "\n",
    "for img in nor_img:\n",
    "    path = nor_fr_path + f'/{img}'\n",
    "    nor_fr_list_path.append(path)\n",
    "\n",
    "# nor_fr_list_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b112dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsd_img = os.listdir(vsd_fr_path)\n",
    "vsd_fr_list_path = list()\n",
    "\n",
    "for img in vsd_img:\n",
    "    path = vsd_fr_path + f'/{img}'\n",
    "    vsd_fr_list_path.append(path)\n",
    "\n",
    "# vsd_fr_list_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a335fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'path': nor_fr_list_path, 'label': 0})\n",
    "df = pd.concat([df, pd.DataFrame({'path': vsd_fr_list_path, 'label': 1})])\n",
    "x = df['path']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad787409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages (from imbalanced-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d686cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_scalar_nan' from 'sklearn.utils' (/home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/sklearn/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01munder_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[32m      2\u001b[39m rus = RandomUnderSampler()\n\u001b[32m      3\u001b[39m x_res, y_res = rus(x, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/imblearn/__init__.py:52\u001b[39m\n\u001b[32m     48\u001b[39m     sys.stderr.write(\u001b[33m\"\u001b[39m\u001b[33mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     53\u001b[39m         combine,\n\u001b[32m     54\u001b[39m         ensemble,\n\u001b[32m     55\u001b[39m         exceptions,\n\u001b[32m     56\u001b[39m         metrics,\n\u001b[32m     57\u001b[39m         over_sampling,\n\u001b[32m     58\u001b[39m         pipeline,\n\u001b[32m     59\u001b[39m         tensorflow,\n\u001b[32m     60\u001b[39m         under_sampling,\n\u001b[32m     61\u001b[39m         utils,\n\u001b[32m     62\u001b[39m     )\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/imblearn/combine/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_enn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_tomek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[32m      8\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mSMOTEENN\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSMOTETomek\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/imblearn/combine/_smote_enn.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/imblearn/base.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _OneToOneFeatureMixin \u001b[38;5;28;01mas\u001b[39;00m OneToOneFeatureMixin\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m label_binarize\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/sklearn/preprocessing/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`sklearn.preprocessing` module includes scaling, centering,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mnormalization, binarization methods.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     Binarizer,\n\u001b[32m      8\u001b[39m     KernelCenterer,\n\u001b[32m      9\u001b[39m     MaxAbsScaler,\n\u001b[32m     10\u001b[39m     MinMaxScaler,\n\u001b[32m     11\u001b[39m     Normalizer,\n\u001b[32m     12\u001b[39m     PowerTransformer,\n\u001b[32m     13\u001b[39m     QuantileTransformer,\n\u001b[32m     14\u001b[39m     RobustScaler,\n\u001b[32m     15\u001b[39m     StandardScaler,\n\u001b[32m     16\u001b[39m     add_dummy_feature,\n\u001b[32m     17\u001b[39m     binarize,\n\u001b[32m     18\u001b[39m     maxabs_scale,\n\u001b[32m     19\u001b[39m     minmax_scale,\n\u001b[32m     20\u001b[39m     normalize,\n\u001b[32m     21\u001b[39m     power_transform,\n\u001b[32m     22\u001b[39m     quantile_transform,\n\u001b[32m     23\u001b[39m     robust_scale,\n\u001b[32m     24\u001b[39m     scale,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_discretization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KBinsDiscretizer\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_encoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, OrdinalEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:44\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparsefuncs_fast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     35\u001b[39m     inplace_csr_row_normalize_l1,\n\u001b[32m     36\u001b[39m     inplace_csr_row_normalize_l2,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     39\u001b[39m     FLOAT_DTYPES,\n\u001b[32m     40\u001b[39m     _check_sample_weight,\n\u001b[32m     41\u001b[39m     check_is_fitted,\n\u001b[32m     42\u001b[39m     check_random_state,\n\u001b[32m     43\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_encoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[32m     46\u001b[39m BOUNDS_THRESHOLD = \u001b[32m1e-7\u001b[39m\n\u001b[32m     48\u001b[39m __all__ = [\n\u001b[32m     49\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBinarizer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mKernelCenterer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpower_transform\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, OneToOneFeatureMixin, TransformerMixin, _fit_context\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, check_array, is_scalar_nan\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_encode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _check_unknown, _encode, _get_counts, _unique\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mask\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_mask\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_scalar_nan' from 'sklearn.utils' (/home/kadafi/Documents/AWU/Heart-Leaks-Disease-Classification/venv/lib/python3.12/site-packages/sklearn/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "x_res, y_res = rus(x, y)\n",
    "x_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1097d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_path, output_path, img_size=(224, 224)):\n",
    "    for path in input_path:\n",
    "        img = tf.keras.preprocessing.image.load_img(path, target_size=img_size)\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "        img_array = img_array / 255.0\n",
    "        img_uint8 = tf.image.convert_image_dtype(img_array, dtype=tf.uint8)\n",
    "\n",
    "        filename = os.path.basename(path)\n",
    "        filename = os.path.splitext(filename)[0] + '.png'\n",
    "\n",
    "        output_file = os.path.join(output_path, filename)\n",
    "\n",
    "        tf.keras.utils.save_img(output_file, img_uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bde17000",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(nor_fr_list_path, nor_prepro_path)\n",
    "preprocess(vsd_fr_list_path, vsd_prepro_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
